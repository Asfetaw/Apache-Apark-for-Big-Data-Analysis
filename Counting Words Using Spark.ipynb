{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Counting Using Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Library and create the Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "#We can create a SparkConf() object and use it to initialize the spark context\n",
    "conf = SparkConf().setAppName(\"Collinear Points\").setMaster(\"local[4]\") #Initialize spark context using 4 local cores as workers\n",
    "sc = SparkContext(conf=conf)    \n",
    "\n",
    "from pyspark.rdd import RDD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the File \n",
    "Define an RDD that will read the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download File From S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 asfetu 197121 1257260 Jul 11 23:54 ../../Data/Moby-Dick.txt\n",
      "Wall time: 1.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##If this cell fails, download the file from https://mas-dse-open.s3.amazonaws.com/Moby-Dick.txt on your browser\n",
    "# and put it in the '../../Data/ directory\n",
    "import requests\n",
    "data_dir='../../Data'\n",
    "filename='Moby-Dick.txt'\n",
    "url = \"https://mas-dse-open.s3.amazonaws.com/\"+filename\n",
    "local_path = data_dir+'/'+filename\n",
    "#!mkdir -p {data_dir}\n",
    "# Copy URL content to local_path\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open(local_path, 'wb').write(r.content)\n",
    "\n",
    "# check that the text file is where we expect it to be\n",
    "!ls -l $local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text_file=sc.textFile(local_path)\n",
    "text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## steps for counting words \n",
    "*  split line by space\n",
    "*  Map each to tupe as (word,1)\n",
    "*  Count the number of words occurance of each word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=text_file.flatMap(lambda line:line.split(\" \") ) # Generate A long list of word \n",
    "not_empty=words.filter(lambda x:x!=' ')     # clean up operation , remove all empty space recoded as words in the aove list\n",
    "key_values=not_empty.map(lambda word:(word,1)) # map words to (word,1)\n",
    "counts= key_values.reduceByKey(lambda a,b:a+b) # for each key sum the value , that is counting the number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words in the file is: 219480\n"
     ]
    }
   ],
   "source": [
    "## Counting the number of words and sum up all words in the file \n",
    "Count=counts.count()  # count the number of words\n",
    "Sum=counts.map(lambda x:x[1]).reduce(lambda x,y:x+y) # x[1] is value of the key-value pair. sumup all the values \n",
    "print(\"The number of total words in the file is:\",Sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219480"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The number of different words \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean number of  occurance per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.497"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(Sum/Count,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 Using chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pairs=text_file.flatMap(lambda x: x.split(' '))\\\n",
    "    .filter(lambda x: x!='')\\\n",
    "    .map(lambda word: (word,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counts occurance of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts=word_pairs.reduceByKey(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse (word,count) to (count,word) and sort by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_counts=counts.map(lambda x:(x[1],x[0]))   # reverse order of word and count\n",
    "sorted_counts=reverse_counts.sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Top 5 most common words words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words\n",
      "13766:\tthe\n",
      "6587:\tof\n",
      "5951:\tand\n",
      "4533:\ta\n",
      "4510:\tto\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(13766, 'the'), (6587, 'of'), (5951, 'and'), (4533, 'a'), (4510, 'to')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D=sorted_counts.take(5)\n",
    "print('most common words\\n'+'\\n'.join(['%d:\\t%s'%c for c in D]))\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
